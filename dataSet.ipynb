{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50bd9230-063b-4d7e-959e-cf6b07a90f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current OS: Linux\n",
      "CUDA: True\n",
      "Python Version: 3.8.5\n",
      "torch Version: 1.9.0+cu102\n",
      "torchvision Version: 0.8.2\n"
     ]
    }
   ],
   "source": [
    "# 현재 OS 및 라이브러리 버전 체크 체크\n",
    "current_os = platform.system()\n",
    "print(f\"Current OS: {current_os}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "print(f\"torch Version: {torch.__version__}\")\n",
    "print(f\"torchvision Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bccfa44-71f9-4b41-aeb1-e0946d5c4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import random\n",
    "import platform\n",
    "import warnings\n",
    "import collections\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda0e0b1-5dee-4b28-a8e2-ad0946eb531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b190c758-4cd0-484f-9fde-481d8a0318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef0668be-76dd-4114-8a3e-feab82e3c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b821d73e-e455-4b2f-9cec-bd6c65ac1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833e4c84-0b19-4ef4-b371-edcbcabb22f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "TRAIN_MY_PATH = {\n",
    "    'trainCsv' : os.path.join(test_dir, 'train.csv'),\n",
    "    'image' : os.path.join(test_dir, 'images')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00a3a942-8338-4329-80d7-3451e00fd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainDataset(Dataset) :\n",
    "    def __init__(self, path, transform, train=True):\n",
    "        self.img_data = pd.read_csv(path['trainCsv'])\n",
    "        self.img_dir = path['image']\n",
    "        self.classes = ['id', 'gender', 'race', 'age']\n",
    "        \n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.path = path\n",
    "        self._repr_indent = 4\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.img_data)\n",
    "    \n",
    "    def __getitem__(self, idx) :\n",
    "        person_path = os.path.join(self.img_dir, self.img_data.iloc[idx,4])\n",
    "        incorrect_mask_img_path = os.path.join(person_path, 'incorrect_mask.jpg')\n",
    "        print(incorrect_mask_img_path)\n",
    "        image = Image.open(incorrect_mask_img_path)\n",
    "        id = self.img_data.iloc[idx, 0]\n",
    "        if self.transform :\n",
    "            image = self.transform(image)\n",
    "        return image, id\n",
    "    \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        https://github.com/pytorch/vision/blob/master/torchvision/datasets/vision.py\n",
    "        '''\n",
    "        head = \"(Inform) My Custom Dataset\"\n",
    "        data_path = self._repr_indent*\" \" + \"Data path: {}\".format(self.path['image'])\n",
    "        label_path = self._repr_indent*\" \" + \"Label path: {}\".format(self.path['trainCsv'])\n",
    "        num_data = self._repr_indent*\" \" + \"Number of datapoints: {}\".format(self.__len__())\n",
    "        num_classes = self._repr_indent*\" \" + \"Number of classes: {}\".format(len(self.classes))\n",
    "\n",
    "        return '\\n'.join([head,\n",
    "                          data_path, label_path, \n",
    "                          num_data, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49f5f171-9902-407f-b4ba-133402c6733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_My = MyTrainDataset(path = TRAIN_MY_PATH,\n",
    "                                  transform = transforms.ToTensor(),\n",
    "                                  train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8095201-352e-4c64-9539-81539100e4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Inform) My Custom Dataset\n",
       "    Data path: /opt/ml/input/data/train/images\n",
       "    Label path: /opt/ml/input/data/train/train.csv\n",
       "    Number of datapoints: 2700\n",
       "    Number of classes: 4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train_My"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b17cf70-fe6c-44b6-90de-a2a808c53b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train_My)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eeec8ea8-3fc5-46c2-a773-6ad79f977534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/input/data/train/images/000001_female_Asian_45/incorrect_mask.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.7490, 0.7490, 0.7490,  ..., 0.7882, 0.7882, 0.7882],\n",
       "          [0.7490, 0.7490, 0.7490,  ..., 0.7882, 0.7882, 0.7882],\n",
       "          [0.7490, 0.7490, 0.7490,  ..., 0.7882, 0.7882, 0.7882],\n",
       "          ...,\n",
       "          [0.5843, 0.5882, 0.5882,  ..., 0.5922, 0.5922, 0.5922],\n",
       "          [0.5725, 0.5725, 0.5725,  ..., 0.5961, 0.5961, 0.5961],\n",
       "          [0.5608, 0.5608, 0.5608,  ..., 0.6078, 0.6078, 0.6078]],\n",
       " \n",
       "         [[0.7451, 0.7451, 0.7451,  ..., 0.7843, 0.7843, 0.7843],\n",
       "          [0.7451, 0.7451, 0.7451,  ..., 0.7843, 0.7843, 0.7843],\n",
       "          [0.7451, 0.7451, 0.7451,  ..., 0.7843, 0.7843, 0.7843],\n",
       "          ...,\n",
       "          [0.3804, 0.3843, 0.3843,  ..., 0.3686, 0.3686, 0.3686],\n",
       "          [0.3686, 0.3686, 0.3686,  ..., 0.3725, 0.3725, 0.3725],\n",
       "          [0.3569, 0.3569, 0.3569,  ..., 0.3686, 0.3686, 0.3686]],\n",
       " \n",
       "         [[0.7255, 0.7255, 0.7255,  ..., 0.7647, 0.7647, 0.7647],\n",
       "          [0.7255, 0.7255, 0.7255,  ..., 0.7647, 0.7647, 0.7647],\n",
       "          [0.7255, 0.7255, 0.7255,  ..., 0.7647, 0.7647, 0.7647],\n",
       "          ...,\n",
       "          [0.2353, 0.2392, 0.2392,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2235, 0.2235, 0.2235,  ..., 0.2667, 0.2667, 0.2667],\n",
       "          [0.2118, 0.2118, 0.2118,  ..., 0.2863, 0.2863, 0.2863]]]),\n",
       " '000001')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = next(iter(dataset_train_My))\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3715ef-df8d-4a1a-ae1e-a0e9f157db01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
